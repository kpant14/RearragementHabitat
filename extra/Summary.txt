Input size (MB): 0.66
Forward/backward pass size (MB): 86.30
Params size (MB): 78.90
Estimated Total Size (MB): 165.86
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 16, 236, 236]           1,216
         MaxPool2d-2         [-1, 16, 118, 118]               0
              ReLU-3         [-1, 16, 118, 118]               0
            Conv2d-4         [-1, 16, 114, 114]           6,416
         MaxPool2d-5           [-1, 16, 57, 57]               0
              ReLU-6           [-1, 16, 57, 57]               0
            Conv2d-7          [-1, 512, 12, 12]         205,312
         Rearrange-8             [-1, 144, 512]               0
           Dropout-9             [-1, 144, 512]               0
PositionalEncoding-10             [-1, 144, 512]               0
          Dropout-11             [-1, 144, 512]               0
        LayerNorm-12             [-1, 144, 512]           1,024
           Linear-13            [-1, 144, 1536]         786,432
           Linear-14            [-1, 144, 1536]         786,432
           Linear-15             [-1, 144, 768]         393,216
          Dropout-16          [-1, 3, 144, 144]               0
ScaledDotProductAttention-17          [-1, 3, 144, 256]               0
           Linear-18             [-1, 144, 512]         393,216
          Dropout-19             [-1, 144, 512]               0
        LayerNorm-20             [-1, 144, 512]           1,024
MultiHeadAttention-21             [-1, 144, 512]               0
           Linear-22            [-1, 144, 1024]         525,312
           Linear-23             [-1, 144, 512]         524,800
          Dropout-24             [-1, 144, 512]               0
        LayerNorm-25             [-1, 144, 512]           1,024
PositionwiseFeedForward-26             [-1, 144, 512]               0
     EncoderLayer-27             [-1, 144, 512]               0
           Linear-28            [-1, 144, 1536]         786,432
           Linear-29            [-1, 144, 1536]         786,432
           Linear-30             [-1, 144, 768]         393,216
          Dropout-31          [-1, 3, 144, 144]               0
ScaledDotProductAttention-32          [-1, 3, 144, 256]               0
           Linear-33             [-1, 144, 512]         393,216
          Dropout-34             [-1, 144, 512]               0
        LayerNorm-35             [-1, 144, 512]           1,024
MultiHeadAttention-36             [-1, 144, 512]               0
           Linear-37            [-1, 144, 1024]         525,312
           Linear-38             [-1, 144, 512]         524,800
          Dropout-39             [-1, 144, 512]               0
        LayerNorm-40             [-1, 144, 512]           1,024
PositionwiseFeedForward-41             [-1, 144, 512]               0
     EncoderLayer-42             [-1, 144, 512]               0
           Linear-43            [-1, 144, 1536]         786,432
           Linear-44            [-1, 144, 1536]         786,432
           Linear-45             [-1, 144, 768]         393,216
          Dropout-46          [-1, 3, 144, 144]               0
ScaledDotProductAttention-47          [-1, 3, 144, 256]               0
           Linear-48             [-1, 144, 512]         393,216
          Dropout-49             [-1, 144, 512]               0
        LayerNorm-50             [-1, 144, 512]           1,024
MultiHeadAttention-51             [-1, 144, 512]               0
           Linear-52            [-1, 144, 1024]         525,312
           Linear-53             [-1, 144, 512]         524,800
          Dropout-54             [-1, 144, 512]               0
        LayerNorm-55             [-1, 144, 512]           1,024
PositionwiseFeedForward-56             [-1, 144, 512]               0
     EncoderLayer-57             [-1, 144, 512]               0
           Linear-58            [-1, 144, 1536]         786,432
           Linear-59            [-1, 144, 1536]         786,432
           Linear-60             [-1, 144, 768]         393,216
          Dropout-61          [-1, 3, 144, 144]               0
ScaledDotProductAttention-62          [-1, 3, 144, 256]               0
           Linear-63             [-1, 144, 512]         393,216
          Dropout-64             [-1, 144, 512]               0
        LayerNorm-65             [-1, 144, 512]           1,024
MultiHeadAttention-66             [-1, 144, 512]               0
           Linear-67            [-1, 144, 1024]         525,312
           Linear-68             [-1, 144, 512]         524,800
          Dropout-69             [-1, 144, 512]               0
        LayerNorm-70             [-1, 144, 512]           1,024
PositionwiseFeedForward-71             [-1, 144, 512]               0
     EncoderLayer-72             [-1, 144, 512]               0
           Linear-73            [-1, 144, 1536]         786,432
           Linear-74            [-1, 144, 1536]         786,432
           Linear-75             [-1, 144, 768]         393,216
          Dropout-76          [-1, 3, 144, 144]               0
ScaledDotProductAttention-77          [-1, 3, 144, 256]               0
           Linear-78             [-1, 144, 512]         393,216
          Dropout-79             [-1, 144, 512]               0
        LayerNorm-80             [-1, 144, 512]           1,024
MultiHeadAttention-81             [-1, 144, 512]               0
           Linear-82            [-1, 144, 1024]         525,312
           Linear-83             [-1, 144, 512]         524,800
          Dropout-84             [-1, 144, 512]               0
        LayerNorm-85             [-1, 144, 512]           1,024
PositionwiseFeedForward-86             [-1, 144, 512]               0
     EncoderLayer-87             [-1, 144, 512]               0
           Linear-88            [-1, 144, 1536]         786,432
           Linear-89            [-1, 144, 1536]         786,432
           Linear-90             [-1, 144, 768]         393,216
          Dropout-91          [-1, 3, 144, 144]               0
ScaledDotProductAttention-92          [-1, 3, 144, 256]               0
           Linear-93             [-1, 144, 512]         393,216
          Dropout-94             [-1, 144, 512]               0
        LayerNorm-95             [-1, 144, 512]           1,024
MultiHeadAttention-96             [-1, 144, 512]               0
           Linear-97            [-1, 144, 1024]         525,312
           Linear-98             [-1, 144, 512]         524,800
          Dropout-99             [-1, 144, 512]               0
       LayerNorm-100             [-1, 144, 512]           1,024
PositionwiseFeedForward-101             [-1, 144, 512]               0
    EncoderLayer-102             [-1, 144, 512]               0
================================================================
Total params: 20,682,704
Trainable params: 20,682,704
Non-trainable params: 0
----------------------------------------------------------------


Input size (MB): 0.57
Forward/backward pass size (MB): 62.79
Params size (MB): 42.64
Estimated Total Size (MB): 105.99
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19          [-1, 128, 28, 28]          73,728
      BatchNorm2d-20          [-1, 128, 28, 28]             256
             ReLU-21          [-1, 128, 28, 28]               0
           Conv2d-22          [-1, 128, 28, 28]         147,456
      BatchNorm2d-23          [-1, 128, 28, 28]             256
           Conv2d-24          [-1, 128, 28, 28]           8,192
      BatchNorm2d-25          [-1, 128, 28, 28]             256
             ReLU-26          [-1, 128, 28, 28]               0
       BasicBlock-27          [-1, 128, 28, 28]               0
           Conv2d-28          [-1, 128, 28, 28]         147,456
      BatchNorm2d-29          [-1, 128, 28, 28]             256
             ReLU-30          [-1, 128, 28, 28]               0
           Conv2d-31          [-1, 128, 28, 28]         147,456
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 256, 14, 14]         294,912
      BatchNorm2d-36          [-1, 256, 14, 14]             512
             ReLU-37          [-1, 256, 14, 14]               0
           Conv2d-38          [-1, 256, 14, 14]         589,824
      BatchNorm2d-39          [-1, 256, 14, 14]             512
           Conv2d-40          [-1, 256, 14, 14]          32,768
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
       BasicBlock-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 14, 14]         589,824
      BatchNorm2d-45          [-1, 256, 14, 14]             512
             ReLU-46          [-1, 256, 14, 14]               0
           Conv2d-47          [-1, 256, 14, 14]         589,824
      BatchNorm2d-48          [-1, 256, 14, 14]             512
             ReLU-49          [-1, 256, 14, 14]               0
       BasicBlock-50          [-1, 256, 14, 14]               0
           Conv2d-51            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-52            [-1, 512, 7, 7]           1,024
             ReLU-53            [-1, 512, 7, 7]               0
           Conv2d-54            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
           Conv2d-56            [-1, 512, 7, 7]         131,072
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       BasicBlock-59            [-1, 512, 7, 7]               0
           Conv2d-60            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-61            [-1, 512, 7, 7]           1,024
             ReLU-62            [-1, 512, 7, 7]               0
           Conv2d-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       BasicBlock-66            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
================================================================
Total params: 11,176,512
Trainable params: 11,176,512
Non-trainable params: 0
----------------------------------------------------------------





----------------------------------------------------------------
Input size (MB): 0.28
Forward/backward pass size (MB): 0.00
Params size (MB): 0.01
Estimated Total Size (MB): 0.29
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
         Rearrange-1            [-1, 512, 1, 1]               0
            Conv2d-2              [-1, 3, 1, 1]           1,539
         Rearrange-3                    [-1, 3]               0
================================================================
Total params: 1,539
Trainable params: 1,539
Non-trainable params: 0
----------------------------------------------------------------
